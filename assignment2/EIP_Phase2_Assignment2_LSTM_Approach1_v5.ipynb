{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP_Phase2_Assignment2_LSTM_Approach1_v5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5WrzsH3AZhS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bswgJHMzASmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4fvSUS4AUEs",
        "colab_type": "code",
        "outputId": "b9f11511-5032-4b1e-821d-58f8077e02ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trHHlWt8s5wI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bcafff69-0c88-43f0-839e-b480be55035b"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 19.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEl3eS8PCkiQ",
        "colab_type": "code",
        "outputId": "4cfb97d5-6eff-4d70-80c1-b93779cb95ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1iai6zKxrGYIza4k1Kbwb8eTyD4wybYE8'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()[0:500]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded content \"﻿CHAPTER I. Down the Rabbit-Hole\r\n",
            "\r\n",
            "Alice was beginning to get very tired of sitting by her sister on the\r\n",
            "bank, and of having nothing to do: once or twice she had peeped into the\r\n",
            "book her sister was reading, but it had no pictures or conversations in\r\n",
            "it, ‘and what is the use of a book,’ thought Alice ‘without pictures or\r\n",
            "conversations?’\r\n",
            "\r\n",
            "So she was considering in her own mind (as well as she could, for the\r\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure\r\n",
            "of making a da\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65_4MnWVmVIo",
        "colab_type": "text"
      },
      "source": [
        "# How sequences are generated?  \n",
        "Instead of using a sliding window of a fixed size, we add more charcters to our sequence and ask the network to predict the next character.The sequences will be padded so that all of them will be of length 100.If there are sentences longer than 100 characters, then they will be broken down into smaller pieces and the above mentioned approah will be applied on each of the smaller pieces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKq-Wy_hNPDt",
        "colab_type": "code",
        "outputId": "20cf6448-1e51-4a80-fd4e-f0ff5523e5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "sentence=\"jon snow knows nothing\"\n",
        "for i in range(0,len(sentence)):\n",
        "  seq_in=sentence[0:i]\n",
        "  seq_out=sentence[i]\n",
        "  print('input:',seq_in,\".output:\",seq_out)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input:  .output: j\n",
            "input: j .output: o\n",
            "input: jo .output: n\n",
            "input: jon .output:  \n",
            "input: jon  .output: s\n",
            "input: jon s .output: n\n",
            "input: jon sn .output: o\n",
            "input: jon sno .output: w\n",
            "input: jon snow .output:  \n",
            "input: jon snow  .output: k\n",
            "input: jon snow k .output: n\n",
            "input: jon snow kn .output: o\n",
            "input: jon snow kno .output: w\n",
            "input: jon snow know .output: s\n",
            "input: jon snow knows .output:  \n",
            "input: jon snow knows  .output: n\n",
            "input: jon snow knows n .output: o\n",
            "input: jon snow knows no .output: t\n",
            "input: jon snow knows not .output: h\n",
            "input: jon snow knows noth .output: i\n",
            "input: jon snow knows nothi .output: n\n",
            "input: jon snow knows nothin .output: g\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNa-iffxmeKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODLdMa4DcCer",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Text Generation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VCjkBnAtE4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class TextGenerator:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.clean_text=None\n",
        "    self.chars=None\n",
        "    self.char_to_int=None\n",
        "    self.sequence_model=None\n",
        "    self.X=None\n",
        "    self.y=None\n",
        "    self.train_history=None\n",
        "    \n",
        "    \n",
        "  def load_and_clean_text(self,file_content):\n",
        "    \n",
        "    #converting text to lower case\n",
        "    self.clean_text=file_content.lower()\n",
        "    \n",
        "    #strip all of the new line characters so that we have one long sequence of characters separated only by white space.\n",
        "    tokens=self.clean_text.split()\n",
        "    self.clean_text=' '.join(tokens)\n",
        "    \n",
        "    #removing punctuations other than full stop\n",
        "    punctuations_to_remove=''.join([ch for ch in string.punctuation if ch!='.'])\n",
        "    self.clean_text=self.clean_text.translate(str.maketrans('', '', punctuations_to_remove))\n",
        "    self.clean_text=self.clean_text.replace('\\ufeff',\" \").replace('\\n',\" \").replace('\\r',\" \").replace( '‘',\"\").replace('’',\"\").replace('“',\"\").replace('”',\"\").replace(\"  \",\" \")\n",
        "    \n",
        "    # create mapping of unique chars to integers\n",
        "    self.chars = sorted(list(set(self.clean_text)))\n",
        "    \n",
        "    self.char_to_int = dict((c, i) for i, c in enumerate(self.chars))\n",
        "    self.int_to_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "    \n",
        "    self.n_chars = len(self.clean_text)\n",
        "    self.n_vocab = len(self.chars)\n",
        "    print(\"Total Characters: \", self.n_chars)\n",
        "    print(\"Total Vocab: \", self.n_vocab)\n",
        "    \n",
        "    \n",
        "  def prepare_data_set(self,seq_len=100):\n",
        "    #prepare the dataset of input to output pairs encoded as integers\n",
        "    seq_length=seq_len\n",
        "    dataX=[]\n",
        "    dataY=[]\n",
        "    \n",
        "    sentences=self.clean_text.split('.')\n",
        "    \n",
        "    for sentence in sentences:\n",
        "      if len(sentence)<=seq_length:\n",
        "        for i in range(0,len(sentence)):\n",
        "          seq_in=sentence[0:i]\n",
        "          seq_out=sentence[i]\n",
        "          dataX.append([self.char_to_int[char] for char in seq_in])\n",
        "          dataY.append(self.char_to_int[seq_out])\n",
        "      else:\n",
        "        smaller_sentences=[sentence[i:i+seq_length] for i in range(0, len(sentence), seq_length)]\n",
        "        for smaller_sentence in smaller_sentences:\n",
        "          if len(smaller_sentence)<=seq_length:\n",
        "            for i in range(0,len(smaller_sentence)):\n",
        "              seq_in=smaller_sentence[0:i]\n",
        "              seq_out=smaller_sentence[i]\n",
        "              dataX.append([self.char_to_int[char] for char in seq_in])\n",
        "              dataY.append(self.char_to_int[seq_out])\n",
        "              \n",
        "      \n",
        "    n_patterns = len(dataX)\n",
        "    print(\"Total Patterns: \", n_patterns)\n",
        "    dataX_padded=np.array(pad_sequences(dataX, maxlen=seq_length, padding='pre'))\n",
        "    \n",
        "    print('shape of dataX_padded:',dataX_padded.shape)\n",
        "    # reshape X to be [samples, time steps, features]\n",
        "    self.X = np.reshape(dataX_padded, (n_patterns, seq_length, 1))\n",
        "    # normalize\n",
        "    self.X = self.X / float(self.n_vocab)\n",
        "    # one hot encode the output variable\n",
        "    self.y = np_utils.to_categorical(dataY)\n",
        "    \n",
        "    \n",
        "  def create_sequence_model(self,num_lstm_units=256,drop_out=0.1):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(num_lstm_units, input_shape=(self.X.shape[1],self.X.shape[2]),dropout=drop_out,return_sequences=True))\n",
        "    model.add(LSTM(num_lstm_units))\n",
        "    model.add(Dense(self.y.shape[1], activation='softmax'))\n",
        "    \n",
        "    self.sequence_model=model\n",
        "    self.sequence_model.summary()\n",
        "    \n",
        "  def train_model(self,file_path_to_store_weights,\n",
        "                  num_epochs=100,\n",
        "                  batch_size=128,\n",
        "                 loss_fn='categorical_crossentropy',\n",
        "                 optimizer_name='adam'):\n",
        "    \n",
        "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
        "    checkpoint = ModelCheckpoint(filepath=file_path_to_store_weights,\n",
        "                             monitor='loss',\n",
        "                             verbose=1,\n",
        "                             save_weights_only=False,\n",
        "                             save_best_only=False,\n",
        "                             mode='min',\n",
        "                             period=10)\n",
        "    \n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    self.sequence_model.compile(loss=loss_fn, optimizer=optimizer_name)\n",
        "    # fit the model\n",
        "    self.train_history=self.sequence_model.fit(self.X, self.y, epochs=num_epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "    \n",
        "\n",
        "  def predict(self,char_seed='cat',num_chars_to_predict=100):\n",
        "    char_prediction=char_seed\n",
        "    pattern = [self.char_to_int[ch] for ch in char_seed]\n",
        "    print(\"Seed:\",char_seed)\n",
        "  \n",
        "    # generate characters\n",
        "    for i in range(num_chars_to_predict):\n",
        "      x = np.array(pad_sequences([pattern], maxlen=100, padding='pre'))\n",
        "      x=np.reshape(x, (1, 100, 1))\n",
        "      x = x / float(self.n_vocab)\n",
        "      prediction = self.sequence_model.predict(x, verbose=0)\n",
        "      index = np.argmax(prediction)\n",
        "      result = self.int_to_char[index]\n",
        "      seq_in = [self.int_to_char[value] for value in pattern]\n",
        "      char_prediction+=result\n",
        "      pattern.append(index)\n",
        "      pattern = pattern[1:len(pattern)]\n",
        "  \n",
        "    return char_prediction\n",
        "  \n",
        "  \n",
        "  def predict_with_temperature(self,char_seed='cat',num_chars_to_predict=100,temperature=1):\n",
        "    char_prediction=char_seed\n",
        "    pattern = [self.char_to_int[ch] for ch in char_seed]\n",
        "#     print(\"Seed:\",char_seed)\n",
        "  \n",
        "    # generate characters\n",
        "    for i in range(num_chars_to_predict):\n",
        "      x = np.array(pad_sequences([pattern], maxlen=100, padding='pre'))\n",
        "      x=np.reshape(x, (1, 100, 1))\n",
        "      x = x / float(self.n_vocab)\n",
        "      prediction = self.sequence_model.predict(x, verbose=0)\n",
        "      \n",
        "      preds=np.asarray(prediction).astype('float64')\n",
        "      preds=np.log(preds)/temperature\n",
        "      index = np.argmax(preds)\n",
        "      \n",
        "      result = self.int_to_char[index]\n",
        "      seq_in = [self.int_to_char[value] for value in pattern]\n",
        "      char_prediction+=result\n",
        "      pattern.append(index)\n",
        "      pattern = pattern[1:len(pattern)]\n",
        "  \n",
        "    return char_prediction \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUw_yh8uC8sj",
        "colab_type": "code",
        "outputId": "6ec63543-2dd8-4e60-f97e-fffd44f362b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "txt_generator=TextGenerator()\n",
        "txt_generator.load_and_clean_text(downloaded.GetContentString())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  135043\n",
            "Total Vocab:  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0B6-UYYqKx6",
        "colab_type": "code",
        "outputId": "cab2bc11-b61b-46a7-b569-33bae92c2211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "txt_generator.prepare_data_set(seq_len=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  134054\n",
            "shape of dataX_padded: (134054, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOJCYjfYu9cc",
        "colab_type": "code",
        "outputId": "033bf513-b436-4389-b93a-874c8d91e1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "txt_generator.create_sequence_model(num_lstm_units=256,drop_out=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 28)                7196      \n",
            "=================================================================\n",
            "Total params: 796,700\n",
            "Trainable params: 796,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bH3XScbrjpd",
        "colab_type": "code",
        "outputId": "726f085b-b318-4da5-f6cf-ff01b5efe820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "weights_save_path='/content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:{epoch:03d}.hdf5'\n",
        "txt_generator.train_model(file_path_to_store_weights=weights_save_path,num_epochs=100,batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 2.8186\n",
            "Epoch 2/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 2.6504\n",
            "Epoch 3/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 2.4264\n",
            "Epoch 4/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 2.2695\n",
            "Epoch 5/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 2.1514\n",
            "Epoch 6/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 2.0611\n",
            "Epoch 7/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.9816\n",
            "Epoch 8/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.9183\n",
            "Epoch 9/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.8636\n",
            "Epoch 10/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.8139\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:010.hdf5\n",
            "Epoch 11/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.7736\n",
            "Epoch 12/100\n",
            "134054/134054 [==============================] - 296s 2ms/step - loss: 1.7349\n",
            "Epoch 13/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.6968\n",
            "Epoch 14/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.6710\n",
            "Epoch 15/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.6422\n",
            "Epoch 16/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.6070\n",
            "Epoch 17/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.5802\n",
            "Epoch 18/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.5765\n",
            "Epoch 19/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.5341\n",
            "Epoch 20/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.5099\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:020.hdf5\n",
            "Epoch 21/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.4874\n",
            "Epoch 22/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.4640\n",
            "Epoch 23/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.4493\n",
            "Epoch 24/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.4284\n",
            "Epoch 25/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.4036\n",
            "Epoch 26/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.3818\n",
            "Epoch 27/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.3616\n",
            "Epoch 28/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.3417\n",
            "Epoch 29/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.3207\n",
            "Epoch 30/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.3035\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:030.hdf5\n",
            "Epoch 31/100\n",
            "134054/134054 [==============================] - 293s 2ms/step - loss: 1.2784\n",
            "Epoch 32/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.2597\n",
            "Epoch 33/100\n",
            "134054/134054 [==============================] - 293s 2ms/step - loss: 1.2405\n",
            "Epoch 34/100\n",
            "134054/134054 [==============================] - 293s 2ms/step - loss: 1.2191\n",
            "Epoch 35/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.2134\n",
            "Epoch 36/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.1790\n",
            "Epoch 37/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.1606\n",
            "Epoch 38/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.1384\n",
            "Epoch 39/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.1191\n",
            "Epoch 40/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.0992\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:040.hdf5\n",
            "Epoch 41/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 1.0817\n",
            "Epoch 42/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.0574\n",
            "Epoch 43/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.0376\n",
            "Epoch 44/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 1.0174\n",
            "Epoch 45/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.9988\n",
            "Epoch 46/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.9780\n",
            "Epoch 47/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.9607\n",
            "Epoch 48/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.9467\n",
            "Epoch 49/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.9241\n",
            "Epoch 50/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.9037\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:050.hdf5\n",
            "Epoch 51/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.8878\n",
            "Epoch 52/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.8675\n",
            "Epoch 53/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.8539\n",
            "Epoch 54/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.8319\n",
            "Epoch 55/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.8158\n",
            "Epoch 56/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.8020\n",
            "Epoch 57/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.7857\n",
            "Epoch 58/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.7690\n",
            "Epoch 59/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.7544\n",
            "Epoch 60/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.7397\n",
            "\n",
            "Epoch 00060: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:060.hdf5\n",
            "Epoch 61/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.7250\n",
            "Epoch 62/100\n",
            "134054/134054 [==============================] - 298s 2ms/step - loss: 0.7108\n",
            "Epoch 63/100\n",
            "134054/134054 [==============================] - 296s 2ms/step - loss: 0.6989\n",
            "Epoch 64/100\n",
            "134054/134054 [==============================] - 296s 2ms/step - loss: 0.6816\n",
            "Epoch 65/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.6748\n",
            "Epoch 66/100\n",
            "134054/134054 [==============================] - 298s 2ms/step - loss: 0.6640\n",
            "Epoch 67/100\n",
            "134054/134054 [==============================] - 298s 2ms/step - loss: 0.6474\n",
            "Epoch 68/100\n",
            "134054/134054 [==============================] - 294s 2ms/step - loss: 0.6324\n",
            "Epoch 69/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.6224\n",
            "Epoch 70/100\n",
            "134054/134054 [==============================] - 302s 2ms/step - loss: 0.6083\n",
            "\n",
            "Epoch 00070: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:070.hdf5\n",
            "Epoch 71/100\n",
            "134054/134054 [==============================] - 299s 2ms/step - loss: 0.5938\n",
            "Epoch 72/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.5933\n",
            "Epoch 73/100\n",
            "134054/134054 [==============================] - 297s 2ms/step - loss: 0.5776\n",
            "Epoch 74/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.5744\n",
            "Epoch 75/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.5637\n",
            "Epoch 76/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.5523\n",
            "Epoch 77/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.5404\n",
            "Epoch 78/100\n",
            "134054/134054 [==============================] - 295s 2ms/step - loss: 0.5341\n",
            "Epoch 79/100\n",
            "134054/134054 [==============================] - 214s 2ms/step - loss: 0.5269\n",
            "Epoch 80/100\n",
            "134054/134054 [==============================] - 142s 1ms/step - loss: 0.5147\n",
            "\n",
            "Epoch 00080: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:080.hdf5\n",
            "Epoch 81/100\n",
            "134054/134054 [==============================] - 142s 1ms/step - loss: 0.5121\n",
            "Epoch 82/100\n",
            "134054/134054 [==============================] - 142s 1ms/step - loss: 0.5051\n",
            "Epoch 83/100\n",
            "134054/134054 [==============================] - 143s 1ms/step - loss: 0.4985\n",
            "Epoch 84/100\n",
            "134054/134054 [==============================] - 142s 1ms/step - loss: 0.4893\n",
            "Epoch 85/100\n",
            "117248/134054 [=========================>....] - ETA: 18s - loss: 0.4849"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AI_IaKova99",
        "colab_type": "text"
      },
      "source": [
        "##Epochs 81 to 100  \n",
        "We will retrain the model from epoch 81.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT62Zuo2QoWf",
        "colab_type": "code",
        "outputId": "7b7e292e-e224-4662-8e28-b6b9a38dab39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "txt_generator=TextGenerator()\n",
        "txt_generator.load_and_clean_text(downloaded.GetContentString())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  135043\n",
            "Total Vocab:  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiA9O3QlvlEm",
        "colab_type": "code",
        "outputId": "65cb9431-b160-4d91-a00f-ee7dc506e106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "txt_generator.prepare_data_set(seq_len=100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  134054\n",
            "shape of dataX_padded: (134054, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hlkjdP0vlIf",
        "colab_type": "code",
        "outputId": "f206c570-983b-4ed9-ce02-8ab1715c468a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "txt_generator.create_sequence_model(num_lstm_units=256,drop_out=0.1)\n",
        "txt_generator.sequence_model.load_weights(\"/content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_001_100:080.hdf5\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 28)                7196      \n",
            "=================================================================\n",
            "Total params: 796,700\n",
            "Trainable params: 796,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVFBv1zHwKj-",
        "colab_type": "code",
        "outputId": "b88dd1d1-6a2a-42ac-c9d8-32cb75dfd2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "weights_save_path='/content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_081_100:{epoch:03d}.hdf5'\n",
        "txt_generator.train_model(file_path_to_store_weights=weights_save_path,num_epochs=20,batch_size=512)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.5184\n",
            "Epoch 2/20\n",
            "134054/134054 [==============================] - 158s 1ms/step - loss: 0.5034\n",
            "Epoch 3/20\n",
            "134054/134054 [==============================] - 156s 1ms/step - loss: 0.4936\n",
            "Epoch 4/20\n",
            "134054/134054 [==============================] - 155s 1ms/step - loss: 0.4958\n",
            "Epoch 5/20\n",
            "134054/134054 [==============================] - 156s 1ms/step - loss: 0.4831\n",
            "Epoch 6/20\n",
            "134054/134054 [==============================] - 157s 1ms/step - loss: 0.4777\n",
            "Epoch 7/20\n",
            "134054/134054 [==============================] - 155s 1ms/step - loss: 0.4688\n",
            "Epoch 8/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4689\n",
            "Epoch 9/20\n",
            "134054/134054 [==============================] - 158s 1ms/step - loss: 0.4620\n",
            "Epoch 10/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4529\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_081_100:010.hdf5\n",
            "Epoch 11/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4518\n",
            "Epoch 12/20\n",
            "134054/134054 [==============================] - 160s 1ms/step - loss: 0.4465\n",
            "Epoch 13/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4466\n",
            "Epoch 14/20\n",
            "134054/134054 [==============================] - 160s 1ms/step - loss: 0.4384\n",
            "Epoch 15/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4376\n",
            "Epoch 16/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4319\n",
            "Epoch 17/20\n",
            "134054/134054 [==============================] - 155s 1ms/step - loss: 0.4209\n",
            "Epoch 18/20\n",
            "134054/134054 [==============================] - 159s 1ms/step - loss: 0.4150\n",
            "Epoch 19/20\n",
            "134054/134054 [==============================] - 158s 1ms/step - loss: 0.4126\n",
            "Epoch 20/20\n",
            "134054/134054 [==============================] - 157s 1ms/step - loss: 0.4167\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_081_100:020.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCCTKCxAgIMl",
        "colab_type": "text"
      },
      "source": [
        "## Predicting 500 characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqgzRkJJNkP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a92cae77-0692-457f-e81f-2fa0c71c9038"
      },
      "source": [
        "txt_generator=TextGenerator()\n",
        "txt_generator.load_and_clean_text(downloaded.GetContentString())\n",
        "txt_generator.prepare_data_set(seq_len=100)\n",
        "txt_generator.create_sequence_model(num_lstm_units=256,drop_out=0.1)\n",
        "txt_generator.sequence_model.load_weights(\"/content/gdrive/My Drive/EIP/Phase2/Assignment2/weights/approach1_v5/July_26/epochs_081_100:020.hdf5\")\n",
        "txt_generator.sequence_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  135043\n",
            "Total Vocab:  28\n",
            "Total Patterns:  134054\n",
            "shape of dataX_padded: (134054, 100)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 28)                7196      \n",
            "=================================================================\n",
            "Total params: 796,700\n",
            "Trainable params: 796,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBmkI3GKgLwU",
        "colab_type": "code",
        "outputId": "d449c0d3-e261-42d0-a791-2bde60141a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "prediction=txt_generator.predict(char_seed='alice wants to',num_chars_to_predict=500)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: alice wants to\n",
            "alice wants to meared afrarteraledped ly oow gorustaod bnd tmmed whats note thal thely uif whought a\n",
            "llce iilgs arowher degtcde anice asked ln a ponee of ier ase teepv it anl clovs ttmce harde anl roe \n",
            "sffgly iad ntrked anl round again to her iil sichly iad asmeoonoe bllce hasdly gear whe corksr anice\n",
            " had froe the in had frigd thale io the whoug tlees wher saws so alice hade been an ofst tte clngsaw\n",
            " w vningnngxt waid the lnut tuested hell and a somaee of pne said alice anrnget hestet wn her donse the hreat qut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN6Q_NnVKnaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "336f2a90-1658-4745-eb3c-cf5061bce659"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='alice wants to',num_chars_to_predict=500,temperature=0.2)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice wants to meared afrarteraledped ly oow gorustaod bnd tmmed whats note thal thely uif whought a\n",
            "llce iilgs arowher degtcde anice asked ln a ponee of ier ase teepv it anl clovs ttmce harde anl roe \n",
            "sffgly iad ntrked anl round again to her iil sichly iad asmeoonoe bllce hasdly gear whe corksr anice\n",
            " had froe the in had frigd thale io the whoug tlees wher saws so alice hade been an ofst tte clngsaw\n",
            " w vningnngxt waid the lnut tuested hell and a somaee of pne said alice anrnget hestet wn her donse the hreat qut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7_tFrneLB4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8707871b-4e3e-48a6-9ba3-b73097655d58"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='alice wants to',num_chars_to_predict=500,temperature=0.5)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice wants to meared afrarteraledped ly oow gorustaod bnd tmmed whats note thal thely uif whought a\n",
            "llce iilgs arowher degtcde anice asked ln a ponee of ier ase teepv it anl clovs ttmce harde anl roe \n",
            "sffgly iad ntrked anl round again to her iil sichly iad asmeoonoe bllce hasdly gear whe corksr anice\n",
            " had froe the in had frigd thale io the whoug tlees wher saws so alice hade been an ofst tte clngsaw\n",
            " w vningnngxt waid the lnut tuested hell and a somaee of pne said alice anrnget hestet wn her donse the hreat qut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2TNuoz4LFPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fe2f5807-d641-4ecd-f66f-151a7caaaa81"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='alice wants to',num_chars_to_predict=500,temperature=1)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice wants to meared afrarteraledped ly oow gorustaod bnd tmmed whats note thal thely uif whought a\n",
            "llce iilgs arowher degtcde anice asked ln a ponee of ier ase teepv it anl clovs ttmce harde anl roe \n",
            "sffgly iad ntrked anl round again to her iil sichly iad asmeoonoe bllce hasdly gear whe corksr anice\n",
            " had froe the in had frigd thale io the whoug tlees wher saws so alice hade been an ofst tte clngsaw\n",
            " w vningnngxt waid the lnut tuested hell and a somaee of pne said alice anrnget hestet wn her donse the hreat qut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zg9Kr2FLk-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c8fd3e21-87ea-484a-f8bd-68d425d0cf6f"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='alice wants to',num_chars_to_predict=500,temperature=1.2)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice wants to meared afrarteraledped ly oow gorustaod bnd tmmed whats note thal thely uif whought a\n",
            "llce iilgs arowher degtcde anice asked ln a ponee of ier ase teepv it anl clovs ttmce harde anl roe \n",
            "sffgly iad ntrked anl round again to her iil sichly iad asmeoonoe bllce hasdly gear whe corksr anice\n",
            " had froe the in had frigd thale io the whoug tlees wher saws so alice hade been an ofst tte clngsaw\n",
            " w vningnngxt waid the lnut tuested hell and a somaee of pne said alice anrnget hestet wn her donse the hreat qut \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26r40omQPwoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52aKq0NSgf3E",
        "colab_type": "code",
        "outputId": "5edd7e5c-c5e7-41dd-f44b-b59dc022d677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "prediction=txt_generator.predict(char_seed='jon snow knows nothing',num_chars_to_predict=500)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: jon snow knows nothing\n",
            "jon snow knows nothing fay he conled inm foinveny trum vhe vhoug ture but semember tuestellng what a\n",
            " momgnt as she whole party suall ier agr anl hall and must tueak das cett inttant inl stuppper whe m\n",
            "ing said cytinngng soand when suder waiting tisters and muoked suite po wie toatcrpl it vhingseatt i\n",
            "t whink as i meare ier wail an of vathesdst anxiouse and the sathen deutainly said to the hell asked\n",
            " alice had tomnkng again and sulle the whoskeeisgollfve imp crmfnd deingst tlg in the sawher suadenlng taid to tee it agra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP3wovNYMOy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7161047d-dc8f-4efc-89c9-4e3b48d7930c"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='jon snow knows nothing',num_chars_to_predict=500,temperature=0.2)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jon snow knows nothing fay he conled inm foinveny trum vhe vhoug ture but semember tuestellng what a\n",
            " momgnt as she whole party suall ier agr anl hall and must tueak das cett inttant inl stuppper whe m\n",
            "ing said cytinngng soand when suder waiting tisters and muoked suite po wie toatcrpl it vhingseatt i\n",
            "t whink as i meare ier wail an of vathesdst anxiouse and the sathen deutainly said to the hell asked\n",
            " alice had tomnkng again and sulle the whoskeeisgollfve imp crmfnd deingst tlg in the sawher suadenlng taid to tee it agra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNATMkGDMO3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4f0b5843-2d77-4f8a-e282-0f4c17167d33"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='jon snow knows nothing',num_chars_to_predict=500,temperature=0.5)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jon snow knows nothing fay he conled inm foinveny trum vhe vhoug ture but semember tuestellng what a\n",
            " momgnt as she whole party suall ier agr anl hall and must tueak das cett inttant inl stuppper whe m\n",
            "ing said cytinngng soand when suder waiting tisters and muoked suite po wie toatcrpl it vhingseatt i\n",
            "t whink as i meare ier wail an of vathesdst anxiouse and the sathen deutainly said to the hell asked\n",
            " alice had tomnkng again and sulle the whoskeeisgollfve imp crmfnd deingst tlg in the sawher suadenlng taid to tee it agra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BmpAqTxMO8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8cfe447c-2c9b-490f-cba5-7bca6b77c764"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='jon snow knows nothing',num_chars_to_predict=500,temperature=1)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jon snow knows nothing fay he conled inm foinveny trum vhe vhoug ture but semember tuestellng what a\n",
            " momgnt as she whole party suall ier agr anl hall and must tueak das cett inttant inl stuppper whe m\n",
            "ing said cytinngng soand when suder waiting tisters and muoked suite po wie toatcrpl it vhingseatt i\n",
            "t whink as i meare ier wail an of vathesdst anxiouse and the sathen deutainly said to the hell asked\n",
            " alice had tomnkng again and sulle the whoskeeisgollfve imp crmfnd deingst tlg in the sawher suadenlng taid to tee it agra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vJuPwpZM4jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "abf8f5d3-94d6-4877-c58b-de66146c9171"
      },
      "source": [
        "prediction=txt_generator.predict_with_temperature(char_seed='jon snow knows nothing',num_chars_to_predict=500,temperature=1.2)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jon snow knows nothing fay he conled inm foinveny trum vhe vhoug ture but semember tuestellng what a\n",
            " momgnt as she whole party suall ier agr anl hall and must tueak das cett inttant inl stuppper whe m\n",
            "ing said cytinngng soand when suder waiting tisters and muoked suite po wie toatcrpl it vhingseatt i\n",
            "t whink as i meare ier wail an of vathesdst anxiouse and the sathen deutainly said to the hell asked\n",
            " alice had tomnkng again and sulle the whoskeeisgollfve imp crmfnd deingst tlg in the sawher suadenlng taid to tee it agra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PkJtwQ9QuSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkEY3XlaRzgz",
        "colab_type": "text"
      },
      "source": [
        "## Some more examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu0LPk4sgi9d",
        "colab_type": "code",
        "outputId": "efcd0efb-311c-461e-c34b-28e4bf4a7f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "prediction=txt_generator.predict(char_seed='a lannister always',num_chars_to_predict=500)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: a lannister always\n",
            "a lannister always waid the rabbitsrrt tucnd pf the addusachabt shasly and fo hntotsw tdiaid iv apd \n",
            "senarked tome oiedly put hou temame ovt at a grcit all mysty townded heard yould klehes delply temar\n",
            "ke imayong the hot dried tationing sepldpy toall bgain and said clttoaone oi the lowide holng hear b\n",
            " bycy weacypionsety hasd an i tueatly how bny hav bats taid to tisw its chml tff hoodeaathonses anic\n",
            "e coashed alas the waie the hattinler ttupidts alice wholeles suestery and mnoked suasrellng anl the wented of a grode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzxV5ba-gmPM",
        "colab_type": "code",
        "outputId": "55e53c1d-66e7-4826-97ee-48ed0df85d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "prediction=txt_generator.predict(char_seed='the meaning of life is',num_chars_to_predict=500)\n",
        "print(prediction[0:100])\n",
        "print(prediction[100:200])\n",
        "print(prediction[200:300])\n",
        "print(prediction[300:400])\n",
        "print(prediction[400:])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: the meaning of life is\n",
            "the meaning of life is a vort of crokusts tuaane asp at all eire the nosking oo roe teguhd hird it a\n",
            "ll todes tharply about hot thg way onv suu it made ir ooce as she looked suuping swier tealing hir v\n",
            "aid alice and i whinking the wholeysee the had frund taid the ling a boovery of whem i canled uumori\n",
            "te toale and thonted at round as i uaidnt wtimt to tee if whoug to agteed the lfaving whem and the w\n",
            "hole put bumsset what whan im the wail tus it to a soees the wholey toasmellgoy taid to the halfeued heresale iye kunger a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ines19Ogp8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi9HY_iglc5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}